<!-- font: frutiger -->

![alt text](https://github.com/mattiasvillani/ML4industry/raw/master/Slides/images/MachineLearning.jpg "ML for industry")

<div style="background-color:#eaeff7; padding:20px 47px;">

### Course information
**The typical participant** has a degree in engineering, finance or other quantitative fields. We recommend that participants have taken at least one course in each of the following subjects:

* linear algebra
* calculus
* statistics
* programming

**Software** (recommended): Scikit-learn for Python, TensorFlow.

**Examination**: based on reports from the computer labs.

**Grades**: Pass or Fail.

</div>

\

<div style="background-color:#eaeff7; padding:20px 47px;">

### Course organization and suggested study plan

The course will organized in three half days and three full days. \
The lectures are by design rather condensed. \
It is therefore **highly recommended** that the course participants:

1. Read the suggested course material **before** each lecture. 
2. Use the lecture as a repetition, as an alternative viewpoint, as an opportunity to ask questions, and to deepen your understanding.
3. Attend the lab session to apply the learned methods in practice, to further your understanding and to solidify your knowledge.

Note: the scheduled three hours for each lab will not to be sufficient for completing the lab. 

</div>

\

<div style="background-color:#eaeff7; padding:20px 30px;">

### Teachers
##### Lecturer
Mattias Villani \
Division of Statistics and Machine Learning, Linköping University \
Department of Statistics, Stockholm University

##### Lab assistant
XXX YYY \
Division of Statistics and Machine Learning, Linköping University 

</div>

\

<div style="background-color:#eaeff7; padding:20px 47px;">

#### Day 1
##### 09-10 Lecture 1 - Course intro. Intro to ML. Motivating applications.

Reading: [Slides](https://github.com/mattiasvillani/ESOBE2017/raw/master/Slides/GPregression.pdf) | Chapters 2.1-2.5 in [GPML](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \
Code: \
Other material: \
Software: [Google's TensorFlow](https://www.tensorflow.org/)

##### 10-11 Lecture 2 - Probability and statistics refresher.

Reading: [Slides](https://github.com/mattiasvillani/ESOBE2017/raw/master/Slides/GPregression.pdf) | Chapters 2.1-2.5 in [GPML](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \
Code: \
Other material: \
Software: [Google's TensorFlow](https://www.tensorflow.org/)

##### 11-12 Lecture 3 - Regression.

Reading: [Slides](https://github.com/mattiasvillani/ESOBE2017/raw/master/Slides/GPregression.pdf) | Chapters 2.1-2.5 in [GPML](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \
Code: \
Other material: \
Software: [Google's TensorFlow](https://www.tensorflow.org/)

</div>
\

<div style="background-color:#eaeff7; padding:20px 47px;">

#### Day 2
##### 09-10 Lecture 4 - Regression trees.

Reading: [Slides](https://github.com/mattiasvillani/ESOBE2017/raw/master/Slides/GPregression.pdf) | Chapters 2.1-2.5 in [GPML](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \
Code: \
Other material: \
Software: [Google's TensorFlow](https://www.tensorflow.org/)

##### 10-11 Lecture 5 - Random forest.

Reading: [Slides](https://github.com/mattiasvillani/ESOBE2017/raw/master/Slides/GPregression.pdf) | Chapters 2.1-2.5 in [GPML](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \
Code: \
Other material: \
Software: [Google's TensorFlow](https://www.tensorflow.org/)

##### 11-12 Lecture 6 - Model evaluation.

Reading: [Slides](https://github.com/mattiasvillani/ML4Industry/raw/master/Slides/LectureIntro.pdf) | Chapters 2.1-2.5 in [GPML](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \
Code: \
Other material: \


##### 13-16 Computer Lab 1 - Regression.

Reading: Lab \
Submission tool:
</div>

\
<div style="background-color:#eaeff7; padding:20px 47px;">

#### Day 3
##### 09-10 Lecture 7 - Maximum likelihood. Gradient-based optimization.

Reading: \
Code: \
Other material: \
Software: 

##### 10-11 Lecture 8 - Bayesian learning

Reading: \
Code: \
Other material: \
Software: 

##### 11-12 Lecture 9 - Overfitting and regularization

Reading: \
Code: \
Other material: \
Software: 
</div>

\
<div style="background-color:#eaeff7; padding:20px 47px;">

#### Day 4
##### 09-10 Lecture 10 - Classification. Naive Bayes.

Reading: \
Code: \
Other material: \
Software: 

##### 10-11 Lecture 11 - Logistic regression.

Reading: \
Code: \
Other material: \
Software: 

##### 11-12 Lecture 12 - Unsupervised learning. Clustering. Mixture models.

Reading: \
Code: \
Other material: \
Software: 

##### 13-16 Computer Lab 2 - Clustering. Classification.

Reading: Lab \
Submission tool:
</div>

\
<div style="background-color:#eaeff7; padding:20px 47px;">

#### Day 5
##### 09-10 Lecture 13 - Deep Neural networks.

Reading: \
Code: \
Other material: \
Software: 

##### 10-11 Lecture 14 - Learning Deep neural networks.

Reading: \
Code: \
Other material: \
Software: 

##### 11-12 Lecture 15 - Convolutional Neural networks.

Reading: \
Code: \
Other material: \
Software: 
</div>

\
<div style="background-color:#eaeff7; padding:20px 47px;">

#### Day 6
##### 09-10 Lecture 16 - Decision making under uncertainty.

Reading: \
Code: \
Other material: \
Software: 

##### 10-11 Lecture 17 - Reinforcement learning.

Reading: \
Code: \
Other material: \
Software: 

##### 11-12 Lecture 18 -  Reinforcement learning.

Reading: \
Code: \
Other material: \
Software: 

##### 13-16 Computer Lab 3 - Deep learning. Reinforcement learning.

Reading: Lab \
Submission tool:

</div>

\
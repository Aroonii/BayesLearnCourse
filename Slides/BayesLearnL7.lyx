#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\usetheme{focus}


\title{Machine Learning for Industry}
\subtitle{Lecture 7: Gibbs sampling. Data augmentaton.}
\author[Mattias Villani]{Mattias Villani}
%\titlegraphic{\includegraphics[scale=0.1]{Images/BayesTheoremNeon}}
\institute{Linköping University 
\\ Stockholm University  
\vspace{0.1cm} \\ }



\definecolor{blue}{RGB}{38, 122, 181}
%\definecolor{blue}{RGB}{102, 159, 204}
\definecolor{orange}{RGB}{255, 128, 0}
\definecolor{red}{RGB}{255, 128, 0}
\end_preamble
\options xcolor=svgnames
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "palatino" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Bayesian Learning
\end_layout

\end_inset

Bayesian Statistics - Lecture 7
\end_layout

\begin_layout Author
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Mattias Villani
\end_layout

\end_inset

Mattias Villani
\end_layout

\begin_layout Institute

\series bold
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\series bold
SU and LiU
\end_layout

\end_inset

Department of Statistics
\begin_inset Newline newline
\end_inset

Stockholm University
\begin_inset Newline newline
\end_inset

and
\begin_inset Newline newline
\end_inset

Department of Computer and Information Science
\begin_inset Newline newline
\end_inset

Linköping University
\end_layout

\begin_layout Date
\begin_inset space \thinspace{}
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Lecture overview
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Monte Carlo simulation and random number generation
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Gibbs sampling
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Data augmentation
\series default
\color inherit

\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Mixture models
\end_layout

\begin_layout Itemize

\series bold
\color blue
Probit regression
\begin_inset VSpace bigskip
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\color blue
Regularized regression revisited
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Monte Carlo sampling
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $\theta^{(1)},\theta^{(2)},....,\theta^{(N)}$
\end_inset

 is an 
\series bold
\color blue

\begin_inset Formula $iid$
\end_inset

 sequence
\series default
\color inherit
 from a distribution 
\begin_inset Formula $p(\theta)$
\end_inset

, then
\begin_inset Formula 
\begin{eqnarray*}
\frac{1}{N}\sum_{t=1}^{N}\theta^{(t)} & \rightarrow & E(\theta)\\
\frac{1}{N}\sum_{t=1}^{N}g(\theta^{(t)}) & \rightarrow & E[g(\theta)]
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $g(\theta)$
\end_inset

 is some well-behaved function.
\end_layout

\begin_layout Itemize
Easy to compute 
\series bold
tail probabilities
\series default
 
\begin_inset Formula $\mathrm{Pr}(\theta\leq c)$
\end_inset

 by letting 
\begin_inset Formula 
\[
g(\theta)=I\left(\theta\leq c\right)
\]

\end_inset

and 
\begin_inset Formula 
\[
\frac{1}{N}\sum_{t=1}^{N}g(\theta^{(t)})=\frac{\#\text{ }\theta\text{-draws smaller than }c}{N}.
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\size larger
Direct sampling by the
\size default
 
\size larger
inverse CDF
\begin_inset space \space{}
\end_inset

method
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
How to 
\series bold
\color blue
simulate
\series default
\color inherit
 from a distribution?
\end_layout

\begin_layout Itemize
Let 
\begin_inset Formula $f(x)$
\end_inset

 be the density function of a stochastic variable.
 CDF: 
\begin_inset Formula $F(x)$
\end_inset

.
 
\series bold
\color blue
Inverse CDF
\begin_inset space \space{}
\end_inset

method
\series default
\color inherit
:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Generate 
\begin_inset Formula $u$
\end_inset

 from the uniform distribution on 
\begin_inset Formula $[0,1]$
\end_inset

.
\end_layout

\begin_layout Enumerate
Compute 
\begin_inset Formula $x=F^{-1}(u)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
Example 1: 
\series bold
Exponential
\series default
 
\series bold
distribution
\series default
: 
\begin_inset Formula 
\[
u=F(x)=1-\exp(-\lambda x)
\]

\end_inset

Inverting gives
\begin_inset Formula 
\[
x=-\ln(1-u)/\lambda
\]

\end_inset

But 
\begin_inset Formula $1-u$
\end_inset

 is also uniformly distributed on [0,1].
 So:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $x=-(\ln u)/\lambda$
\end_inset

 where 
\begin_inset Formula $u\sim Unif(0,1)$
\end_inset

, then 
\begin_inset Formula $x\sim Expon(\lambda)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Inverse CDF method, discrete case
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/InverseCDF.pdf
	scale 35

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\size larger
Direct sampling by the
\size default
 
\size larger
inverse CDF
\begin_inset space \space{}
\end_inset

method
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Example 2: 
\series bold
\color blue
Cauchy distribution
\series default
\color inherit
: 
\begin_inset Formula 
\begin{eqnarray*}
f(x) & = & \frac{1}{\pi}\frac{1}{1+x^{2}}\\
u & = & F(x)=\frac{1}{2}+\frac{1}{\pi}\arctan(x)
\end{eqnarray*}

\end_inset

Inverting ...
\begin_inset Formula 
\[
x=\tan[\pi(u-1/2)].
\]

\end_inset


\end_layout

\begin_layout Itemize
We can also use relations between distribution to sample from distributions.
\end_layout

\begin_layout Itemize
Cauchy-example, cont.
 If 
\begin_inset Formula $y$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 are independent 
\begin_inset Formula $N(0,1)$
\end_inset

 variables, then 
\begin_inset Formula $z=\frac{y}{z}\sim Cauchy$
\end_inset

.
\end_layout

\begin_layout Itemize
Example: 
\series bold
\color blue
Chi-square
\series default
\color inherit
.
 If 
\begin_inset Formula $x_{1},...,x_{v}\overset{iid}{\sim}N(0,1)$
\end_inset

, then 
\begin_inset Formula $y=\sum_{i=1}^{v}x_{i}^{2}\sim\chi_{v}^{2}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Easily implemented methods for 
\series bold
\color blue
sampling from multivariate distributions
\series default
\color inherit
, 
\begin_inset Formula $p(\theta_{1},...,\theta_{k})$
\end_inset

.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
Requirements: Easily sampled 
\series bold
\color blue
full conditional posteriors
\series default
\color inherit
:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $p(\theta_{1}|\theta_{2},\theta_{3}...,\theta_{k})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $p(\theta_{2}|\theta_{1},\theta_{3},...,\theta_{k})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $p(\theta_{k}|\theta_{1},\theta_{2},...,\theta_{k-1})$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Started out in the early 80's in the image analysis literature.
\end_layout

\begin_layout Itemize
Gibbs sampling is a 
\series bold
special case of Metropolis-Hastings
\series default
 (see Lecture 8)
\end_layout

\begin_layout Itemize
Metropolis-Hastings is a Markov Chain Monte Carlo (MCMC) algorithm.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The Gibbs sampling algorithm
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset

A:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset

 Choose initial values 
\begin_inset Formula $\theta_{2}^{(0)},\theta_{3}^{(0)},...,\theta_{k}^{(0)}.$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset

B:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset


\begin_inset Formula $B_{1}$
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset

 Draw 
\begin_inset Formula $\theta_{1}^{(1)}$
\end_inset

 from 
\begin_inset Formula $p(\theta_{1}|\theta_{2}^{(0)},\theta_{3}^{(0)},...,\theta_{k}^{(0)})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset


\begin_inset Formula $B_{2}$
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset

 Draw 
\begin_inset Formula $\theta_{2}^{(1)}$
\end_inset

 from 
\begin_inset Formula $p(\theta_{2}|\theta_{1}^{(1)},\theta_{3}^{(0)},...,\theta_{k}^{(0)})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset

:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset


\begin_inset Formula $B_{n}$
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset

 Draw 
\begin_inset Formula $\theta_{k}^{(1)}$
\end_inset

 from 
\begin_inset Formula $p(\theta_{k}|\theta_{1}^{(1)},\theta_{2}^{(1)},...,\theta_{k-1}^{(1)})$
\end_inset

 
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

[
\end_layout

\end_inset

C:
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

]
\end_layout

\end_inset

 Repeat Step B 
\begin_inset Formula $N$
\end_inset

 times.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling, cont.
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The Gibbs draws 
\begin_inset Formula $\theta^{(1)},\theta^{(2)},....,\theta^{(N)}$
\end_inset

 are 
\series bold
\color blue
dependent
\series default
\color inherit
 (autocorrelated), but 
\series bold
arithmetic means converge to expected values
\series default

\begin_inset Formula 
\begin{eqnarray*}
\frac{1}{N}\sum_{t=1}^{N}\theta_{j}^{(t)} & \rightarrow & E(\theta_{j})\\
\frac{1}{N}\sum_{t=1}^{N}g(\theta^{(t)}) & \rightarrow & E[g(\theta)]
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\theta^{(1)},....,\theta^{(N)}$
\end_inset

 
\series bold
converges in distribution
\series default
 to the target 
\begin_inset Formula $p(\theta)$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\theta_{j}^{(1)},...,\theta_{j}^{(N)}$
\end_inset

 converge to the marginal distribution of 
\begin_inset Formula $\theta_{j}$
\end_inset

, 
\begin_inset Formula $p(\theta_{j})$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
\color blue
Dependent
\series default
\color inherit
 draws 
\begin_inset Formula $\rightarrow$
\end_inset

 
\series bold
\color blue
less efficient
\series default
\color inherit
 than iid sampling.
 
\end_layout

\begin_layout Itemize
Compare sampling from:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $x_{t}\overset{iid}{\sim}N(0,\sigma^{2})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $x_{t}=0.9x_{t-1}+\varepsilon_{t}$
\end_inset

 with 
\begin_inset Formula $\varepsilon_{t}\overset{iid}{\sim}N(0,\sigma^{2})$
\end_inset

.
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling multivariate normal
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Bivariate normal:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Joint distribution
\begin_inset Formula 
\[
\left(\begin{array}{c}
\theta_{1}\\
\theta_{2}
\end{array}\right)\sim N_{2}\left[\left(\begin{array}{c}
\mu_{1}\\
\mu_{2}
\end{array}\right),\left(\begin{array}{cc}
1 & \rho\\
\rho & 1
\end{array}\right)\right]
\]

\end_inset


\end_layout

\begin_layout Itemize
Full conditional posteriors:
\begin_inset Formula 
\begin{eqnarray*}
\theta_{1}|\theta_{2} & \sim & N[\mu_{1}+\rho(\theta_{2}-\mu_{2}),1-\rho^{2}]\\
\theta_{2}|\theta_{1} & \sim & N[\mu_{2}+\rho(\theta_{1}-\mu_{1}),1-\rho^{2}]
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling - Bivariate normal
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/GibbsBivariateNormal1.eps
	scale 50

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling - Bivariate normal
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/GibbsBivariateNormal2.eps
	scale 50

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling - Bivariate normal
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/GibbsBivariateNormal3.eps
	scale 50

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Direct sampling vs Gibbs sampling
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/DirectvsGibbs.png
	scale 32

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Estimating the density of 
\begin_inset Formula $g(\theta_{1},\theta_{2})=\sqrt{\theta_{1}^{2}+\theta_{2}^{2}}$
\end_inset


\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/EstLengthVector.png
	scale 40

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Estimating 
\begin_inset Formula $Pr(\theta_{1}>0,\theta_{2}>0)$
\end_inset


\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We can estimate a joint probability by counting: 
\begin_inset Formula 
\[
Pr(\theta_{1}>0,\theta_{2}>0)\approx N^{-1}\sum_{i=1}^{N}1(\theta_{1}^{(i)}>0,\theta_{2}^{i)}>0)
\]

\end_inset

 .
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/CumsumJointProb.png
	scale 32

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling for normal model with non-conjugate prior
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Normal model with semi-conjugate prior
\begin_inset Formula 
\begin{align*}
\mu & \sim N(\mu_{0},\tau_{0}^{2})\\
\sigma^{2} & \sim Inv-\chi^{2}(\nu_{0},\sigma_{0}^{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
Conditional posteriors
\begin_inset Formula 
\begin{align*}
\mu|\sigma^{2},x & \sim N\left(\mu_{n},\tau_{n}^{2}\right)\\
\sigma^{2}|\mu,x & \sim Inv-\chi^{2}\left(\nu_{n},\frac{\nu_{0}\sigma_{0}^{2}+\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{n+\nu_{0}}\right)
\end{align*}

\end_inset

with 
\begin_inset Formula $\mu_{n}$
\end_inset

 and 
\begin_inset Formula $\tau_{n}^{2}$
\end_inset

 defined the same as when 
\begin_inset Formula $\sigma^{2}$
\end_inset

 is known (Lecture 2).
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling for AR processes
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
AR(
\begin_inset Formula $p$
\end_inset

) process
\series default
\color inherit

\begin_inset Formula 
\[
x_{t}=\mu+\phi_{1}(x_{t-1}-\mu)+...+\phi_{p}(x_{t-p}-\mu)+\varepsilon_{t},\text{ \ \ }\varepsilon_{t}\overset{iid}{\sim}N(0,\sigma^{2}).
\]

\end_inset


\end_layout

\begin_layout Itemize
Let 
\begin_inset Formula $\phi=(\phi_{1},...,\phi_{p})'$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
\color blue
Prior
\series default
\color inherit
: 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\mu\sim$
\end_inset

Normal
\end_layout

\begin_layout Itemize
\begin_inset Formula $\phi\sim$
\end_inset

Multivariate Normal
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma^{2}\sim$
\end_inset

Scaled Inverse 
\begin_inset Formula $\chi^{2}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
The 
\series bold
\color blue
posterior
\series default
\color inherit
 can be simulated by Gibbs sampling:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\mu|\phi,\sigma^{2},x\sim$
\end_inset

 Normal
\end_layout

\begin_layout Itemize
\begin_inset Formula $\text{\phi}|\mu,\sigma^{2},x\sim$
\end_inset

 Multivariate Normal
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma^{2}|\mu,\phi,x\sim$
\end_inset

 Scaled Inverse 
\begin_inset Formula $\chi^{2}$
\end_inset

 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Data augmentation - Mixture distributions 
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Let 
\begin_inset Formula $\phi(x|\mu,\sigma^{2})$
\end_inset

 denotes the 
\series bold
PDF
\series default
 of a 
\series bold
normal
\series default
 variable 
\begin_inset Formula $x\sim N(\mu,\sigma^{2})$
\end_inset

.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Two-component mixture of normals
\series default
\color inherit
 [MN(
\begin_inset Formula $2$
\end_inset

)]
\begin_inset Formula 
\[
p(x)=\pi\cdot\phi(x|\mu_{1},\sigma_{1}^{2})+(1-\pi)\cdot\phi(x|\mu_{2},\sigma_{2}^{2})
\]

\end_inset


\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Simulate
\series default
\color inherit
 from a MN(
\begin_inset Formula $2$
\end_inset

):
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Simulate an indicator 
\begin_inset Formula $I\in\{1,2\}$
\end_inset

: 
\begin_inset Formula $I\sim Bern(\pi)$
\end_inset

.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $I=1$
\end_inset

, simulate 
\begin_inset Formula $x$
\end_inset

 from 
\begin_inset Formula $N(\mu_{1},\sigma_{1}^{2})$
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $I=2$
\end_inset

, simulate 
\begin_inset Formula $x$
\end_inset

 from 
\begin_inset Formula $N(\mu_{2},\sigma_{2}^{2}).$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Illustration of mixture distributions
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename Images/MixtureOfNormals.pdf
	scale 36

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Mixture distributions, cont.
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Not easy to estimate directly - the likelihood is a product of sums.
\end_layout

\begin_layout Itemize

\series bold
Assume
\series default
 that we knew which of the two densities each observation came from.
 
\begin_inset Formula 
\[
I_{i}=\left\{ \begin{array}{c}
1\text{ if }x_{i}\text{ came from Density 1}\\
2\text{ if }x_{i}\text{ came from Density 2}
\end{array}\right..
\]

\end_inset


\end_layout

\begin_layout Itemize
Armed with knowledge of 
\begin_inset Formula $I_{1},...,I_{n}$
\end_inset

 it is now easy to estimate 
\begin_inset Formula $\pi$
\end_inset

, 
\begin_inset Formula $\mu_{1},\sigma_{1}^{2},\mu_{2},\sigma_{2}^{2}$
\end_inset

 by separating the sample according to the 
\begin_inset Formula $I$
\end_inset

's.
\end_layout

\begin_layout Itemize
But we do 
\series bold
not
\series default
 know 
\begin_inset Formula $I_{1},...,I_{n}$
\end_inset

!
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling for mixture distributions
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Prior: 
\begin_inset Formula $\pi$
\end_inset

 
\begin_inset Formula $\sim Beta(\alpha_{1},\alpha_{2})$
\end_inset

.
 Conjugate prior for 
\begin_inset Formula $(\mu_{j},\sigma_{j}^{2}),$
\end_inset

 see Lecture 5.
 
\end_layout

\begin_layout Itemize
Define: 
\begin_inset Formula $n_{1}=\sum\nolimits _{i=1}^{n}(I_{i}=1)$
\end_inset

 and 
\begin_inset Formula $n_{2}=n-n_{1}$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
\color blue
Gibbs sampling
\series default
\color inherit
:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\pi$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\mathbf{I},\mathbf{x}\sim Beta(\alpha_{1}+n_{1},\alpha_{2}+n_{2})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma_{1}^{2}$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\mathbf{I},\mathbf{x}\sim Inv$
\end_inset

-
\begin_inset Formula $\chi^{2}(\nu_{n_{1}},\sigma_{n_{1}}^{2})$
\end_inset

 and 
\begin_inset Formula $\mu_{1}|\mathbf{I},\sigma_{1}^{2},\mathbf{x}\sim N\left(\mu_{n_{1}},\frac{\sigma_{1}^{2}}{\kappa_{n_{1}}}\right)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma_{2}^{2}$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\mathbf{I},\mathbf{x}\sim Inv$
\end_inset

-
\begin_inset Formula $\chi^{2}(\nu_{n_{2}},\sigma_{n_{2}}^{2})$
\end_inset

 and 
\begin_inset Formula $\mu_{2}|\mathbf{I},\sigma_{2}^{2},\mathbf{x}\sim N\left(\mu_{n_{2}},\frac{\sigma_{2}^{2}}{\kappa_{n_{2}}}\right)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $I_{i}$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\pi,\mu_{1},\sigma_{1}^{2},\mu_{2},\sigma_{2}^{2},\mathbf{x}\sim Bern(\theta_{i})$
\end_inset

, 
\begin_inset Formula $i=1,...,n,$
\end_inset


\begin_inset Formula 
\[
\theta_{i}=\frac{(1-\pi)\phi(x_{i};\mu_{2},\sigma_{2}^{2})}{\pi\phi(x_{i};\mu_{1},\sigma_{1}^{2})+(1-\pi)\phi(x_{i};\mu_{2},\sigma_{2}^{2})}.
\]

\end_inset

 
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling for mixture distributions
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
\begin_inset Formula $K$
\end_inset

-component mixture of normals
\series default
\color inherit

\begin_inset Formula 
\[
p(x)=\sum_{k=1}^{K}\pi_{k}\phi(x;\mu_{k},\sigma_{k}^{2}),
\]

\end_inset

where 
\begin_inset Formula $\sum\nolimits _{k=1}^{K}\pi_{k}=1$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
Multi-class indicators
\series default
: 
\begin_inset Formula $I_{i}=k$
\end_inset

 if observation 
\begin_inset Formula $i$
\end_inset

 comes from density 
\begin_inset Formula $k$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
\color blue
Gibbs sampling
\series default
\color inherit
 with 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $(\pi_{1},...,\pi_{K})$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\mathbf{I},\mathbf{x}\sim Dirichlet(\alpha_{1}+n_{1},\alpha_{2}+n_{2},...,\alpha_{K}+n_{K})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma_{k}^{2}$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\mathbf{I},\mathbf{x}\sim Inv$
\end_inset

-
\begin_inset Formula $\chi^{2}$
\end_inset

 and 
\begin_inset Formula $\mu_{k}|\mathbf{I},\sigma_{k}^{2},\mathbf{x}\sim Normal$
\end_inset

, 
\begin_inset space \space{}
\end_inset


\begin_inset space \space{}
\end_inset


\begin_inset Formula $for$
\end_inset

 
\begin_inset Formula $k=1,...,K,$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $I_{i}$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $\pi,\mu,\sigma^{2},\mathbf{x}\sim Multinomial(\theta_{i1},...,\theta_{iK})$
\end_inset

, 
\begin_inset Formula $for$
\end_inset

 
\begin_inset Formula $i=1,...,n,$
\end_inset


\begin_inset Formula 
\[
\theta_{ij}=\frac{\pi_{j}\phi(x_{i};\mu_{j},\sigma_{j}^{2})}{\sum_{r=1}^{k}\pi_{r}\phi(x_{i};\mu_{r},\sigma_{r}^{2})}.
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Gibbs sampling is very powerful for 
\series bold
\color blue
missing data
\series default
\color inherit
 problems.
 
\series bold
\color blue
Semi-supervised learning
\series default
\color inherit
.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Data augmentation - Probit regression
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Probit
\series default
\color inherit
 model:
\begin_inset Formula 
\[
\Pr(y_{i}=1\text{ }|\text{ }x_{i})=\Phi(x_{i}^{T}\beta)
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Random utility formulation
\series default
\color inherit
 of the probit:
\begin_inset Formula 
\begin{eqnarray*}
u_{i} & \sim & N(x_{i}^{T}\beta,1)\\
y_{i} & = & \left\{ \begin{array}{c}
1\text{ \ \ if }u_{i}>0\\
0\text{ \ \ if }u_{i}\leq0
\end{array}.\right.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Check: 
\begin_inset Formula $\Pr(y_{i}=1$
\end_inset

 
\begin_inset Formula $|$
\end_inset

 
\begin_inset Formula $x_{i})=\Pr(u_{i}>0)=1-\Pr(u_{i}\leq0)=1-\Pr(u_{i}-x_{i}^{T}\beta<-x_{i}^{T}\beta)=1-\Phi(-x_{i}^{T}\beta)=\Phi(x_{i}^{T}\beta)$
\end_inset

.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $u=(u_{1},...,u_{n})$
\end_inset

 were observed, then 
\begin_inset Formula $\beta$
\end_inset

 could be analyzed by traditional linear regression.
 But, 
\begin_inset Formula $u$
\end_inset

 is 
\series bold
not observed
\series default
.
 Gibbs sampling to the rescue!
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Gibbs sampling for the Probit regression
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Simulate from joint posterior 
\begin_inset Formula $p(u,\beta|y)$
\end_inset

 iterating between the 
\series bold
\color blue
full conditional posteriors
\series default
\color inherit
: 
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $p(\beta|u,y)$
\end_inset

, which is multivariate normal (this is just a linear regression)
\end_layout

\begin_layout Itemize

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $p(u_{i}|\beta,y),\text{ }i=1,...,n$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
The full conditional posterior distribution of 
\begin_inset Formula $u_{i}$
\end_inset

 is: 
\begin_inset Formula 
\begin{align*}
p(u_{i}|\beta,y) & \propto p(y_{i}|\beta,u_{i})p(u_{i}|\beta)\\
 & =\begin{cases}
N(u_{i}|x_{i}^{\prime}\beta,1) & \text{truncated to }u_{i}\in(-\infty,0]\text{ if }y_{i}=0\\
N(u_{i}|x_{i}^{\prime}\beta,1) & \text{truncated to }u_{i}\in(0,\infty)\text{ if }y_{i}=1
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
Collect the 
\begin_inset Formula $\beta$
\end_inset

-draws.
 A histogram of these draws approximates 
\begin_inset Formula $p(\beta|y)=$
\end_inset

 
\begin_inset Formula $\int p(u,\beta|y)du$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Regularized regression with Gibbs
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Recap: The joint posterior of 
\begin_inset Formula $\beta$
\end_inset

, 
\begin_inset Formula $\sigma^{2}$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

 is
\begin_inset Formula 
\begin{align*}
\beta|\sigma^{2},\lambda,\mathbf{y},\mathbf{X} & \sim N\left(\mu_{n},\Omega_{n}^{-1}\right)\\
\sigma^{2}|\lambda,\mathbf{y},\mathbf{X} & \sim Inv-\chi^{2}\left(\nu_{n},\sigma_{n}^{2}\right)\\
p(\lambda|\mathbf{y},\mathbf{X}) & \propto\sqrt{\frac{\left|\Omega_{0}\right|}{\left|X'X+\Omega_{0}\right|}}\left(\frac{\nu_{n}\sigma_{n}^{2}}{2}\right)^{-\nu_{n}/2}\cdot p(\lambda)
\end{align*}

\end_inset

where 
\begin_inset Formula $p(\lambda)$
\end_inset

 is the Gamma prior for 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Itemize
This is the 
\series bold
\color blue
conditional-marginal decomposition
\series default
\color inherit

\begin_inset Formula 
\[
p(\beta,\sigma^{2},\lambda\vert\mathbf{y},\mathbf{X})=p(\beta\vert\sigma^{2},\lambda,\mathbf{y},\mathbf{X})p(\sigma^{2}\vert\lambda,\mathbf{y},\mathbf{X})p(\lambda\vert\mathbf{y},\mathbf{X})
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
\color blue
Gibbs sampling
\series default
\color inherit
 can instead be used:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Sample 
\begin_inset Formula $\beta\vert\sigma^{2},\lambda,\mathbf{y},\mathbf{X}$
\end_inset

 from Normal
\end_layout

\begin_layout Itemize
Sample 
\begin_inset Formula $\sigma^{2}\vert\beta,\lambda,\mathbf{y},\mathbf{X}$
\end_inset

 from Inv-
\begin_inset Formula $\chi^{2}$
\end_inset


\end_layout

\begin_layout Itemize
Sample 
\begin_inset Formula $\lambda\vert\beta,\sigma^{2},\mathbf{y},\mathbf{X}$
\end_inset

 from Gamma
\end_layout

\end_deeper
\begin_layout Itemize
Note that 
\begin_inset Formula $\lambda$
\end_inset

 is now 
\series bold
easy
\series default
 to simulate 
\series bold
once we condition
\series default
 on 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Improving the efficiency of the Gibbs sampler
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\shape italic
\emph on
\color blue
Efficient blocking
\series default
\shape default
\emph default
\color inherit
.
 Correlated parameters should ideally be included in the same updating block.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\shape italic
\emph on
\color blue
Reparametrization
\series default
\shape default
\emph default
\color inherit
.
 Convergence can improve dramatically in alternative parametrizations.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize

\series bold
\shape italic
\emph on
\color blue
Data augmentation
\series default
\shape default
\emph default
\color inherit
.
 Bring in latent (unobserved) variables that make the full conditional posterior
s more easily sampled (Probit, Mixture models etc).
 Downside: Typically increases the autocorrelation between draws.
\end_layout

\end_deeper
\end_body
\end_document
